version: '3.8'

services:
  # 后端服务
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: llm-chat-backend
    network_mode: host
    environment:
      # 大模型API配置（默认使用 GLM-4，使用 localhost 访问宿主机服务）
      - LLM_API_URL=http://127.0.0.1:11553/v1/chat/completions
      - LLM_MODEL=glm4_32B_chat
      - LLM_API_KEY=glm432b
      # 数据库配置
      - DATABASE_URL=sqlite:////app/db/conversation.db
      # JWT 配置 - 请修改此密钥！
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key-in-production}
      - ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=10080
      # 服务器配置
      - HOST=0.0.0.0
      - PORT=8000
    volumes:
      # 持久化数据库文件
      - backend-db:/app/db
      # 持久化日志
      - backend-logs:/app/logs
    restart: unless-stopped

  # 前端服务
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm-chat-frontend
    ports:
      - "3000:3000"
    environment:
      # 后端 API 地址（容器内部通信）
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - llm-chat-network

  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    container_name: llm-chat-nginx
    network_mode: host
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - backend
      - frontend
    restart: unless-stopped

networks:
  llm-chat-network:
    driver: bridge

volumes:
  backend-db:
  backend-logs:
