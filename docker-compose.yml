version: '3.8'

services:
  # 后端服务
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: llm-chat-backend
    ports:
      - "8000:8000"
    environment:
      # 大模型API配置（默认使用 GLM-4）
      - LLM_API_URL=http://111.19.168.151:11553/v1/chat/completions
      - LLM_MODEL=glm4_32B_chat
      - LLM_API_KEY=glm432b
      # 数据库配置
      - DATABASE_URL=sqlite:///./conversation.db
      # JWT 配置 - 请修改此密钥！
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key-in-production}
      - ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=10080
      # 服务器配置
      - HOST=0.0.0.0
      - PORT=8000
    volumes:
      # 持久化数据库
      - ./backend/conversation.db:/app/conversation.db
      # 持久化日志
      - ./logs/backend:/app/logs
    restart: unless-stopped
    networks:
      - llm-chat-network

  # 前端服务
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm-chat-frontend
    ports:
      - "3000:3000"
    environment:
      # 后端 API 地址（容器内部通信）
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - llm-chat-network

  # Nginx 反向代理 (可选)
  # nginx:
  #   image: nginx:alpine
  #   container_name: llm-chat-nginx
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/llm-chat.conf:/etc/nginx/conf.d/default.conf
  #     - ./nginx/ssl:/etc/nginx/ssl  # SSL 证书目录
  #   depends_on:
  #     - backend
  #     - frontend
  #   restart: unless-stopped
  #   networks:
  #     - llm-chat-network

networks:
  llm-chat-network:
    driver: bridge

volumes:
  backend-data:
  backend-logs:
