services:
  # 后端服务
  backend:
    build:
      context: ../../backend
      dockerfile: Dockerfile
    container_name: llm-chat-backend
    network_mode: host
    environment:
      # 大模型API配置（默认使用 GLM-4，使用 localhost 访问宿主机服务）
      - LLM_API_URL=${LLM_API_URL:-http://127.0.0.1:11553/v1/chat/completions}
      - LLM_MODEL=${LLM_MODEL:-glm4_32B_chat}
      - LLM_API_KEY=${LLM_API_KEY:-glm432b}
      # 数据库配置（容器内路径，映射到宿主机 ../../db）
      - DATABASE_URL=sqlite:////app/db/conversation.db
      # JWT 配置
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key-in-production}
      - ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=10080
      # 服务器配置
      - HOST=0.0.0.0
      - PORT=8000
    volumes:
      # 挂载宿主机数据库目录（与本地部署共享数据库）
      - ../../db:/app/db
      # 挂载宿主机日志目录
      - ../../logs:/app/logs
      # 挂载宿主机上传文件目录（知识库文档）
      - ../../backend/uploads:/app/uploads
    restart: unless-stopped

  # 前端服务
  frontend:
    build:
      context: ../../frontend
      dockerfile: Dockerfile
      args:
        # 构建时传入API地址（通过nginx反向代理，不带端口）
        - NEXT_PUBLIC_API_URL=${FRONTEND_API_URL:-http://111.19.168.151}
    container_name: llm-chat-frontend
    network_mode: host
    depends_on:
      - backend
    restart: unless-stopped

  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    container_name: llm-chat-nginx
    network_mode: host
    volumes:
      - ../../nginx/default.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
